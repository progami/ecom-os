name: CD

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    permissions:
      id-token: write
      contents: write
    env:
      # expose secrets as env; avoid using `secrets.*` in `if:` expressions
      SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
      AWS_ROLE_TO_ASSUME: ${{ secrets.AWS_ROLE_TO_ASSUME }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
      EC2_HOST_SECRET: ${{ secrets.EC2_HOST }}
      EC2_USER_SECRET: ${{ secrets.EC2_USER }}
      EC2_INSTANCE_ID_SECRET: ${{ secrets.EC2_INSTANCE_ID }}
      CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
      ECOMOS_ENV: ${{ secrets.ECOMOS_ENV }}
      EC2_HOST_PUBLIC_KEY: ${{ secrets.EC2_HOST_PUBLIC_KEY }}
    concurrency:
      group: prod-main
      cancel-in-progress: false
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.sha }}
          fetch-depth: 0
      - name: Install tools (ansible, rsync, jq, curl)
        run: |
          sudo apt-get update
          sudo apt-get install -y ansible rsync jq curl
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: corepack enable && corepack prepare pnpm@9.0.0 --activate
      - run: pnpm install

      - name: Validate version consistency
        run: |
          echo "Validating version consistency across monorepo..."
          node scripts/sync-versions.js --check

      - name: Generate Prisma clients
        run: |
          pnpm --filter @ecom-os/auth prisma:generate
          pnpm --filter @ecom-os/wms db:generate
          pnpm --filter @ecom-os/x-plan prisma:generate
        env:
          CENTRAL_DB_URL: postgresql://postgres:postgres@localhost:5432/postgres?schema=auth
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/postgres

      - name: Build Website
        run: pnpm --filter @ecom-os/website build

      - name: Build EcomOS portal
        run: pnpm --filter @ecom-os/ecomos build
        env:
          NEXTAUTH_SECRET: test-nextauth-secret
          CENTRAL_AUTH_SECRET: test-central-secret
          NEXTAUTH_URL: https://example.com/api/auth
          CENTRAL_AUTH_URL: https://example.com
          COOKIE_DOMAIN: .example.com

      - name: Build WMS
        run: pnpm --filter @ecom-os/wms build
        env:
          NEXTAUTH_SECRET: test-nextauth-secret
          CENTRAL_AUTH_SECRET: test-central-secret
          NEXTAUTH_URL: https://example.com/wms/api/auth
          CENTRAL_AUTH_URL: https://example.com
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/postgres
          BASE_PATH: /wms
          NEXT_PUBLIC_BASE_PATH: /wms
          NEXT_PUBLIC_APP_URL: https://example.com/wms
          NEXT_PUBLIC_CENTRAL_AUTH_URL: https://example.com
          CSRF_ALLOWED_ORIGINS: https://example.com,https://example.com/wms

      - name: Build X-Plan
        run: pnpm --filter @ecom-os/x-plan build
        env:
          NEXTAUTH_SECRET: test-nextauth-secret
          CENTRAL_AUTH_SECRET: test-central-secret
          NEXTAUTH_URL: https://example.com/xplan/api/auth
          CENTRAL_AUTH_URL: https://example.com
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/postgres
          BASE_PATH: /xplan
          NEXT_PUBLIC_BASE_PATH: /xplan
          NEXT_PUBLIC_APP_URL: https://example.com/xplan
          NEXT_PUBLIC_CENTRAL_AUTH_URL: https://example.com
          CSRF_ALLOWED_ORIGINS: https://example.com,https://example.com/xplan

      - name: Configure SSH
        run: |
          install -m 600 -D /dev/null ~/.ssh/id_rsa
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa

      - name: Optionally assume AWS role and discover EC2 host
        if: ${{ env.AWS_ROLE_TO_ASSUME != '' && env.AWS_REGION != '' }}
        continue-on-error: true
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Discover EC2 host (if AWS creds available)
        if: ${{ env.AWS_ROLE_TO_ASSUME != '' && env.AWS_REGION != '' }}
        continue-on-error: true
        run: |
          set -euo pipefail
          if [ -n "${EC2_INSTANCE_ID_SECRET:-}" ]; then
            QUERY_OPTS=(--instance-ids "$EC2_INSTANCE_ID_SECRET")
          else
            QUERY_OPTS=(--filters "Name=instance-state-name,Values=running")
          fi
          read INST_ID INST_AZ INST_IP < <(aws ec2 describe-instances "${QUERY_OPTS[@]}" \
            --query 'Reservations[0].Instances[0].[InstanceId,Placement.AvailabilityZone,PublicIpAddress]' --output text || true)
          if [ -z "${INST_IP:-}" ] || [ "${INST_IP}" = "None" ]; then
            echo "No matching EC2 instance with public IP found via AWS lookup" >&2
            exit 0
          fi
          echo "EC2_HOST=$INST_IP" >> $GITHUB_ENV
          echo "EIC_INSTANCE_ID=$INST_ID" >> $GITHUB_ENV
          echo "EIC_INSTANCE_AZ=$INST_AZ" >> $GITHUB_ENV
          echo "Discovered: id=$INST_ID az=$INST_AZ ip=$INST_IP"

      - name: Fallback to secrets for EC2 host and user (if not discovered)
        run: |
          if [ -z "${EC2_HOST:-}" ]; then
            echo "EC2_HOST=${EC2_HOST_SECRET}" >> $GITHUB_ENV
          fi
          echo "EC2_USER=${EC2_USER_SECRET}" >> $GITHUB_ENV

      - name: Determine remote deployment availability
        run: |
          if [ -n "${EC2_HOST:-}" ]; then
            echo "REMOTE_ENABLED=true" >> $GITHUB_ENV
            echo "Remote host resolved: $EC2_HOST"
          else
            echo "::warning title=Remote host unavailable::Skipping remote deploy steps (no EC2_HOST or AWS discovery)." >&2
            echo "REMOTE_ENABLED=false" >> $GITHUB_ENV
          fi

      - name: Configure known_hosts entry
        if: env.REMOTE_ENABLED == 'true'
        run: |
          set -euo pipefail
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh

          # Prefer explicit public key if provided
          if [ -n "${EC2_HOST_PUBLIC_KEY:-}" ]; then
            printf '%s\n' "$EC2_HOST_PUBLIC_KEY" > ~/.ssh/known_hosts
            echo "STRICT_SSH_CHECKING=yes" >> $GITHUB_ENV
          else
            # Fallback: scan host key without requiring fingerprint (best-effort)
            if [ -z "${EC2_HOST:-}" ]; then
              echo "::error title=Missing EC2 host::EC2_HOST must be resolved before configuring known_hosts." >&2
              exit 1
            fi
            scan_output=$(ssh-keyscan -T 15 -H "$EC2_HOST" 2>/dev/null || true)
            if [ -n "$scan_output" ]; then
              printf '%s\n' "$scan_output" > ~/.ssh/known_hosts
              echo "STRICT_SSH_CHECKING=yes" >> $GITHUB_ENV
            else
              # As a last resort, continue with StrictHostKeyChecking=no in subsequent steps
              echo "::warning title=Host key scan failed::Proceeding with StrictHostKeyChecking=no for SSH/Ansible." >&2
              : > ~/.ssh/known_hosts
              echo "STRICT_SSH_CHECKING=no" >> $GITHUB_ENV
            fi
          fi

          chmod 644 ~/.ssh/known_hosts

      - name: Ensure SSH strict checking mode default
        run: |
          # Default to 'no' if not set by previous step
          if [ -z "${STRICT_SSH_CHECKING:-}" ]; then
            echo "STRICT_SSH_CHECKING=no" >> $GITHUB_ENV
          fi

      - name: Generate and inject CI SSH key via EC2 Instance Connect
        if: ${{ env.AWS_ROLE_TO_ASSUME != '' && env.AWS_REGION != '' && env.REMOTE_ENABLED == 'true' }}
        continue-on-error: true
        env:
          OS_USER: ${{ env.EC2_USER_SECRET }}
        run: |
          set -e
          OS_USER=${OS_USER:-ubuntu}
          ssh-keygen -t ed25519 -N '' -f ~/.ssh/ci_key -C ci@github || true
          # Push key via EIC (ephemeral)
          aws ec2-instance-connect send-ssh-public-key \
            --instance-id "$EIC_INSTANCE_ID" \
            --availability-zone "$EIC_INSTANCE_AZ" \
            --instance-os-user "$OS_USER" \
            --ssh-public-key "file://$HOME/.ssh/ci_key.pub"
          # Use ephemeral window to append pubkey permanently
          ssh -o StrictHostKeyChecking=${STRICT_SSH_CHECKING:-no} -i ~/.ssh/ci_key "$OS_USER@$EC2_HOST" \
            "mkdir -p ~/.ssh && touch ~/.ssh/authorized_keys && grep -qxF '$(cat ~/.ssh/ci_key.pub)' ~/.ssh/authorized_keys || echo '$(cat ~/.ssh/ci_key.pub)' >> ~/.ssh/authorized_keys && chmod 700 ~/.ssh && chmod 600 ~/.ssh/authorized_keys"
          # Switch default key for subsequent steps
          install -m 600 -D ~/.ssh/ci_key ~/.ssh/id_rsa

      - name: Check remote disk usage before deploy
        if: env.REMOTE_ENABLED == 'true'
        continue-on-error: true
        env:
          OS_USER: ${{ env.EC2_USER_SECRET }}
        run: |
          set -e
          OS_USER=${OS_USER:-${EC2_USER:-ubuntu}}
          SSH_OPTS="-o StrictHostKeyChecking=${STRICT_SSH_CHECKING:-no}"
          ssh $SSH_OPTS "$OS_USER@$EC2_HOST" bash <<'EOF'
          set -e
          df -h
          echo
          echo "Top-level usage:"
          sudo du -sh /opt/ecom-os /var/log || true
          echo
          echo "/opt/ecom-os breakdown:"
          sudo du -sh /opt/ecom-os/* 2>/dev/null | sort -hr | head || true
          echo
          echo "User cache breakdown:"
          sudo du -sh "$HOME/.local/share/pnpm" "$HOME/.local/state/pnpm" "$HOME/.pnpm-store" 2>/dev/null || true
          sudo du -sh "$HOME/.cache" 2>/dev/null | sort -hr | head || true
          echo
          echo "PM2 logs:"
          sudo du -sh "$HOME/.pm2/logs" 2>/dev/null || true
          EOF

      - name: Update Cloudflare DNS (apex + www) to EC2
        if: env.REMOTE_ENABLED == 'true'
        continue-on-error: true
        env:
          CF_API_TOKEN: ${{ env.CF_API_TOKEN }}
          CF_ZONE_NAME: targonglobal.com
        run: |
          set -e
          if [ -z "${CF_API_TOKEN:-}" ]; then echo "No CF_API_TOKEN provided; skipping DNS update"; exit 0; fi
          echo "Fetching Cloudflare Zone ID for $CF_ZONE_NAME"
          ZONE_RESP=$(curl -s -H "Authorization: Bearer $CF_API_TOKEN" -H "Content-Type: application/json" \
            "https://api.cloudflare.com/client/v4/zones?name=$CF_ZONE_NAME")
          CF_ZONE_ID=$(echo "$ZONE_RESP" | jq -r '.result[0].id')
          if [ -z "$CF_ZONE_ID" ] || [ "$CF_ZONE_ID" = "null" ]; then echo "Zone not found" >&2; exit 1; fi
          upsert_a(){
            local NAME="$1"; local IP="$2"; local PROXIED=${3:-false}
            echo "Upserting A record $NAME -> $IP (proxied=$PROXIED)"
            REC_ID=$(curl -s -H "Authorization: Bearer $CF_API_TOKEN" -H "Content-Type: application/json" \
              "https://api.cloudflare.com/client/v4/zones/$CF_ZONE_ID/dns_records?type=A&name=$NAME" | jq -r '.result[0].id')
            DATA=$(jq -n --arg type A --arg name "$NAME" --arg content "$IP" --argjson proxied $PROXIED '{type:"A",name:$name,content:$content,ttl:120,proxied:$proxied}')
            if [ -n "$REC_ID" ] && [ "$REC_ID" != "null" ]; then
              curl -s -X PUT -H "Authorization: Bearer $CF_API_TOKEN" -H "Content-Type: application/json" \
                "https://api.cloudflare.com/client/v4/zones/$CF_ZONE_ID/dns_records/$REC_ID" --data "$DATA" | jq -r '.success'
            else
              curl -s -X POST -H "Authorization: Bearer $CF_API_TOKEN" -H "Content-Type: application/json" \
                "https://api.cloudflare.com/client/v4/zones/$CF_ZONE_ID/dns_records" --data "$DATA" | jq -r '.success'
            fi
          }
          upsert_a "$CF_ZONE_NAME" "$EC2_HOST" false
          upsert_a "www.$CF_ZONE_NAME" "$EC2_HOST" false
          upsert_a "ecomos.$CF_ZONE_NAME" "$EC2_HOST" false
          upsert_a "wms.$CF_ZONE_NAME" "$EC2_HOST" false

      - name: Write inventory
        if: env.REMOTE_ENABLED == 'true'
        run: |
          mkdir -p infra/ansible/inventory
          echo "[mono]" > infra/ansible/inventory/hosts.ini
          USER_VAL=${EC2_USER:-ubuntu}
          echo "$EC2_HOST ansible_user=$USER_VAL" >> infra/ansible/inventory/hosts.ini

      - name: Show ansible version
        run: ansible --version && ansible-galaxy collection list || true

      - name: Ansible ping EC2
        continue-on-error: true
        if: env.REMOTE_ENABLED == 'true'
        env:
          ANSIBLE_HOST_KEY_CHECKING: 'True'
          ANSIBLE_SSH_COMMON_ARGS: "-o StrictHostKeyChecking=${{ env.STRICT_SSH_CHECKING }} -o ServerAliveInterval=30 -o ConnectionAttempts=10"
        run: |
          echo "[mono]" > infra/ansible/inventory/hosts.ini
          echo "$EC2_HOST ansible_user=${EC2_USER:-ubuntu}" >> infra/ansible/inventory/hosts.ini
          ansible -vvv -i infra/ansible/inventory/hosts.ini mono -m ping

      - name: Deploy via Ansible (monorepo)
        continue-on-error: true
        if: env.REMOTE_ENABLED == 'true'
        env:
          ANSIBLE_HOST_KEY_CHECKING: 'True'
          ANSIBLE_STDOUT_CALLBACK: debug
          ANSIBLE_SSH_COMMON_ARGS: "-o StrictHostKeyChecking=${{ env.STRICT_SSH_CHECKING }} -o ServerAliveInterval=30 -o ConnectionAttempts=10"
          DEPLOY_COMMIT: ${{ github.sha }}
          WEBSITE_ENV: ${{ secrets.WEBSITE_ENV }}
          WMS_ENV: ${{ secrets.WMS_ENV }}
          HRMS_ENV: ${{ secrets.HRMS_ENV }}
          FCC_ENV: ${{ secrets.FCC_ENV }}
          CENTRAL_DB_ENV: ${{ secrets.CENTRAL_DB_ENV }}
          MARGIN_MASTER_ENV: ${{ secrets.MARGIN_MASTER_ENV }}
          JASON_ENV: ${{ secrets.JASON_ENV }}
          ECOMOS_ENV: ${{ secrets.ECOMOS_ENV }}
          XPLAN_ENV: ${{ secrets.XPLAN_ENV }}
        run: |
          set -e
          echo "Inventory:" && cat infra/ansible/inventory/hosts.ini
          ansible-playbook -vvv -i infra/ansible/inventory/hosts.ini infra/ansible/deploy-monorepo.yml

      - name: Post-deploy health checks
        if: env.REMOTE_ENABLED == 'true'
        continue-on-error: true
        id: health_check
        run: |
          set -e
          HOST_IP="$EC2_HOST"
          parse_var() {
            awk -F': *' -v VAR="$1" '$1==VAR {print $2}' infra/ansible/group_vars/all.yml \
              | tr -d '"' \
              | sed -e 's/^ *//' -e 's/ *$//' \
              | tr -d '\n'
          }
          WEBSITE=$(parse_var website_server_name)
          WMS=$(parse_var wms_server_name)
          # Only check active hosts
          REQUIRED=($WEBSITE $WMS)
          OPTIONAL=()
          # host ip retries
          check_host() {
            local host="$1"; local ip="$2"; local retries="${3:-20}"; local path="/"; local i=1
            echo "Checking $host..."
            while [ $i -le "$retries" ]; do
              echo "  Attempt $i/$retries for $host"
              code=$(curl -sS --connect-timeout 5 --max-time 10 -o /dev/null -w "%{http_code}" -H "Host: $host" "http://$ip$path" || echo "000")
              if echo "$code" | grep -Eq '^(20|30)[0-9]$'; then
                echo "  ✓ OK: $host -> HTTP $code"
                return 0
              fi
              echo "  Got HTTP $code, waiting 10s..."
              sleep 10
              i=$((i+1))
            done
            echo "  ✗ FAIL: $host (tried $retries times)"
            return 1
          }
          failures=0
          # Required hosts (allow up to 20 attempts ~3 min max)
          for h in "${REQUIRED[@]}"; do
            if [ -n "$h" ]; then
              check_host "$h" "$HOST_IP" 20 || failures=$((failures+1))
            fi
          done
          # Optional hosts: run in parallel with fewer attempts
          for h in "${OPTIONAL[@]}"; do [ -n "$h" ] && check_host "$h" "$HOST_IP" 10 & done
          wait || true

          if [ "$failures" -gt 0 ]; then
            echo "⚠️  Warning: $failures required host(s) failed health checks"
            echo "Health checks failed but continuing deployment (apps may still be starting)"
            exit 1
          else
            echo "✓ All health checks passed"
            exit 0
          fi

      - name: Create GitHub Release
        if: success() || failure()
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -e

          # Get version from root package.json
          VERSION=$(node -p "require('./package.json').version")

          # Determine which apps were deployed
          DEPLOYED_APPS=""
          if pnpm list --filter @ecom-os/wms --depth 0 &>/dev/null; then
            DEPLOYED_APPS="${DEPLOYED_APPS}- WMS v${VERSION}\n"
          fi
          if pnpm list --filter @ecom-os/website --depth 0 &>/dev/null; then
            DEPLOYED_APPS="${DEPLOYED_APPS}- Website v${VERSION}\n"
          fi
          if pnpm list --filter @ecom-os/ecomos --depth 0 &>/dev/null; then
            DEPLOYED_APPS="${DEPLOYED_APPS}- Ecomos v${VERSION}\n"
          fi
          if pnpm list --filter @ecom-os/x-plan --depth 0 &>/dev/null; then
            DEPLOYED_APPS="${DEPLOYED_APPS}- X-Plan v${VERSION}\n"
          fi

          # Generate release notes with health check status
          HEALTH_STATUS="✓ Passed"
          if [ "${{ steps.health_check.outcome }}" != "success" ]; then
            HEALTH_STATUS="⚠️  Failed (apps may still be starting)"
          fi

          RELEASE_NOTES="## Deployed Applications

          ${DEPLOYED_APPS}
          ## Deployment Info

          - **Commit**: ${{ github.sha }}
          - **Deployed at**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          - **Triggered by**: ${{ github.actor }}
          - **Health Checks**: ${HEALTH_STATUS}

          ## Changes

          See commit history for details.
          "

          # Create or update release for each app
          # WMS Release
          if echo "$DEPLOYED_APPS" | grep -q "WMS"; then
            TAG="wms-${VERSION}"
            if gh release view "$TAG" &>/dev/null; then
              echo "Release $TAG already exists, updating..."
              gh release edit "$TAG" --notes "$RELEASE_NOTES"
            else
              echo "Creating new release $TAG..."
              gh release create "$TAG" \
                --title "WMS v${VERSION}" \
                --notes "$RELEASE_NOTES" \
                --target main
            fi
          fi

          # Website Release
          if echo "$DEPLOYED_APPS" | grep -q "Website"; then
            TAG="website-${VERSION}"
            if gh release view "$TAG" &>/dev/null; then
              echo "Release $TAG already exists, updating..."
              gh release edit "$TAG" --notes "$RELEASE_NOTES"
            else
              echo "Creating new release $TAG..."
              gh release create "$TAG" \
                --title "Website v${VERSION}" \
                --notes "$RELEASE_NOTES" \
                --target main
            fi
          fi

          # Ecomos Release
          if echo "$DEPLOYED_APPS" | grep -q "Ecomos"; then
            TAG="ecomos-${VERSION}"
            if gh release view "$TAG" &>/dev/null; then
              echo "Release $TAG already exists, updating..."
              gh release edit "$TAG" --notes "$RELEASE_NOTES"
            else
              echo "Creating new release $TAG..."
              gh release create "$TAG" \
                --title "Ecomos v${VERSION}" \
                --notes "$RELEASE_NOTES" \
                --target main
            fi
          fi

          # X-Plan Release
          if echo "$DEPLOYED_APPS" | grep -q "X-Plan"; then
            TAG="x-plan-${VERSION}"
            if gh release view "$TAG" &>/dev/null; then
              echo "Release $TAG already exists, updating..."
              gh release edit "$TAG" --notes "$RELEASE_NOTES"
            else
              echo "Creating new release $TAG..."
              gh release create "$TAG" \
                --title "X-Plan v${VERSION}" \
                --notes "$RELEASE_NOTES" \
                --target main
            fi
          fi

          echo "✓ GitHub releases created/updated for version ${VERSION}"
